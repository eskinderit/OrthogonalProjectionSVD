{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2926fe2b",
   "metadata": {},
   "source": [
    "# Classification of MNIST Digits with SVD Decomposition.\n",
    "The task for this exercise is to learn the classification of MNIST digits by using SVD decomposition.\n",
    "Remember that, Given a matrix $X \\in R^{m×n}$ and its SVD decomposition $X = USV^T$ we can prove that\n",
    "an orthogonal base for the space of the columns is given by the first $p$ columns of the matrix $U$, where\n",
    "$p = rank(X)$ is equal to the number of non-zero singular values of $A$.$$ $$\n",
    "We will make use of the space of the columns defined by the $U$ matrix and the following Theorem:\n",
    "#### Theorem 1 \n",
    "*Let’s consider $W$ a subspace of $R^n$ where $dim(W) = s$ and ${w_1, . . . , w_s}$ an orthogonal base of\n",
    "$W$. Given a generic $y \\in R^n$ we have that the projection $y^{\\perp}$ of $y$ onto $W$ has the following form:*\n",
    "$$y^{\\perp} =\\frac{y\\cdot w_1}\n",
    "{w_1 · w_1}w_1+ ··· +\\frac{y \\cdot w_s}{ws \\cdot ws}ws.$$\n",
    "#### Corollary 1.1. \n",
    "*If $X \\in R^{m×n}$ is a given matrix with SVD decomposition $X = USV^T$, since the $p = rank(X)$\n",
    "is the dimension of the space defined by the columns of $X$ and the columns of $U$, $\\{u1,..., up\\}$ are an\n",
    "orthonormal basis for that space, the projection of an m-dimensional vector $y$ on this space can be easily\n",
    "computed as:*$$ $$\n",
    "$$y^{\\perp} = U(U^Ty)$$ $$ $$\n",
    "Thus, consider a binary classification problem, where we want to classificate if a given digit of dimension\n",
    "$m×n$ represents the number 3 or the number 4. We will call refer to the class of the number 3 as $C_1$, and\n",
    "to the class of the number 4 as $C_2$. Suppose that $s_1$ is the number of elements in $C_1$, while $s_2$ is the number\n",
    "of elements in $C_2$. $$ $$\n",
    "If $X_1 \\in R^{mn×s_{1}}$\n",
    "is the matrix such that its columns are a flatten version of each digit in $C_1$, $X_2 \\in R^{mn×s_{2}}$\n",
    "is the matrix such that its columns are a flatten version of each digit in $C_2$, and consider\n",
    "$$X_1 = U_1S_1V_1^T$$\n",
    "$$X_2 = U_2S_2V_2^T$$\n",
    "the SVD decomposition of the two matrices. $$ $$\n",
    "If $y$ in $R^{m×n}$ is a new, unknown digit, we can classify it by first flatten it to a vector of $R^{mn}$, then we\n",
    "can project it to the spaces of $X_0$ and $X_1$ and call them $$ $$\n",
    "$$y^\\perp_1 = U_1(U^T_1y)$$\n",
    "$$y^\\perp_2 = U_2(U^T_2y)$$ $$ $$\n",
    "Thus, $y$ will be classified as $C_1$ if $||y − y^\\perp_1||_2 < ||y − y^\\perp_2||_2$ and vice versa will be classified as $C_2$ if $\\|y − y^{\\perp}_2\\|_2 < \\|y − y^\\perp_1\\|_2$. We want to implement this idea on Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcd8d8",
   "metadata": {},
   "source": [
    "## First Exercise - Binary classification algorithm\n",
    "In the first exercise, we will implement the binary classification algorithm for the digits 3 and 4 of MNIST following the ideas explained above. \n",
    "\n",
    "   • Load the MNIST dataset contained in **./data/MNIST.mat** with the function **scipy.io.loadmat.** This dataset, which is\n",
    "   loaded in the form of a 256 ×1707 matrix $X$, contains the flattened version of 1707 16 × 16 grayscale handwritten digits.\n",
    "   Moreover, from the same file it is possible to load a vector $I$ of length 1707 such that the $i$-th element of $I$ is the\n",
    "   true digit represented by the $i$-th image of $X$.\n",
    "\n",
    "   • Visualize a bunch of datapoints of $X$ with the function **plt.imshow**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00076fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def display_img():\n",
    "    # Load the data\n",
    "    data = scipy.io.loadmat(r'.\\data\\MNIST.mat')\n",
    "\n",
    "    X = data['X']\n",
    "    I = data['I']\n",
    "    I = I[0,:]\n",
    "\n",
    "    # Visualize an image\n",
    "\n",
    "    \n",
    "    \n",
    "    fig, axs = plt.subplots(2, 4)\n",
    "    fig.suptitle('Vertically stacked subplots')\n",
    "    \n",
    "    axs[0][0].imshow(np.reshape(X[:,0],(16, 16)), cmap='gray')\n",
    "    axs[0][1].imshow(np.reshape(X[:,1],(16, 16)), cmap='gray')\n",
    "    axs[0][2].imshow(np.reshape(X[:,2],(16, 16)), cmap='gray')\n",
    "    axs[0][3].imshow(np.reshape(X[:,3],(16, 16)), cmap='gray')\n",
    "    axs[1][0].imshow(np.reshape(X[:,4],(16, 16)), cmap='gray')\n",
    "    axs[1][1].imshow(np.reshape(X[:,5],(16, 16)), cmap='gray')\n",
    "    axs[1][2].imshow(np.reshape(X[:,6],(16, 16)), cmap='gray')\n",
    "    axs[1][3].imshow(np.reshape(X[:,7],(16, 16)), cmap='gray')\n",
    "    \n",
    "    \n",
    "display_img()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dba3c6",
   "metadata": {},
   "source": [
    "   • Extract from $X$ those columns that corresponds to digits 3 or 4. Those digits represents the classes $C_1$ and $C_2$\n",
    "   defined above.\n",
    "   \n",
    "   • Split the obtained dataset in training and testing. From now on, we will only consider the training set. The test set will\n",
    "   be only used at the end of the exercise to test the algorithm.\n",
    "   \n",
    "   • Create the matrices $X_1$ and $X_2$ defined above from $X$.\n",
    "   \n",
    "   • Compute the SVD decomposition of $X_1$ and $X_2$ with **np.linalg.svd(matrix, full matrices=False)** and denote \n",
    "   the $U$-part of the two decompositions as $U_1$ and $U_2$.\n",
    "   \n",
    "   • Take an unknown digit $y$ from the test set, and compute $y^\\perp_1 = U_1(U^T_1y)$ and $y^\\perp_2 = U_2(U^T_2y)$.\n",
    "   \n",
    "   • Compute the distances $d_1 = \\|y-y^\\perp_1\\|_2$ and $d_2 = \\|y-y^\\perp_2\\|_2$ and classify $y$ to $C_1$ if $d1 < d2$ and\n",
    "   to $C_2$ if $d2 < d1$.\n",
    "   \n",
    "   • Repeat the experiment for different values of $y$ in the test set. Compute the misclassification number for this\n",
    "   algorithm.\n",
    "   \n",
    "   • Repeat the experiment for different digits other than 3 or 4. There is a relationship between the visual similarity of the\n",
    "   digits and the classification error?\n",
    "   \n",
    "   • Comment the obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ab65da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  3  elements:  106\n",
      "Class:  4  elements:  96\n",
      "\n",
      "Digits to classify: [3, 4]\n",
      "Testing:  20.0 %\n",
      "total tests: 51\n",
      "passed tests: 50\n",
      "accuracy:  98.0392156862745  %\n",
      "misclassification number:  1.9607843137254974  %\n",
      "_________________________________\n",
      "Class:  3  elements:  24\n",
      "Class:  4  elements:  26\n",
      "\n",
      "Digits to classify: [3, 4]\n",
      "Testing:  80.0 %\n",
      "total tests: 203\n",
      "passed tests: 200\n",
      "accuracy:  98.52216748768473  %\n",
      "misclassification number:  1.477832512315274  %\n",
      "_________________________________\n",
      "Class:  1  elements:  54\n",
      "Class:  4  elements:  20\n",
      "\n",
      "Digits to classify: [1, 4]\n",
      "Testing:  80.0 %\n",
      "total tests: 300\n",
      "passed tests: 290\n",
      "accuracy:  96.66666666666667  %\n",
      "misclassification number:  3.3333333333333286  %\n",
      "_________________________________\n",
      "Class:  8  elements:  31\n",
      "Class:  9  elements:  24\n",
      "\n",
      "Digits to classify: [8, 9]\n",
      "Testing:  80.0 %\n",
      "total tests: 221\n",
      "passed tests: 220\n",
      "accuracy:  99.5475113122172  %\n",
      "misclassification number:  0.4524886877828038  %\n",
      "_________________________________\n",
      "Class:  5  elements:  18\n",
      "Class:  6  elements:  29\n",
      "\n",
      "Digits to classify: [5, 6]\n",
      "Testing:  80.0 %\n",
      "total tests: 192\n",
      "passed tests: 187\n",
      "accuracy:  97.39583333333334  %\n",
      "misclassification number:  2.604166666666657  %\n",
      "_________________________________\n",
      "Class:  3  elements:  24\n",
      "Class:  8  elements:  31\n",
      "\n",
      "Digits to classify: [3, 8]\n",
      "Testing:  80.0 %\n",
      "total tests: 220\n",
      "passed tests: 211\n",
      "accuracy:  95.9090909090909  %\n",
      "misclassification number:  4.0909090909090935  %\n",
      "_________________________________\n",
      "Class:  1  elements:  50\n",
      "Class:  7  elements:  33\n",
      "\n",
      "Digits to classify: [1, 7]\n",
      "Testing:  80.0 %\n",
      "total tests: 335\n",
      "passed tests: 331\n",
      "accuracy:  98.80597014925372  %\n",
      "misclassification number:  1.1940298507462757  %\n",
      "_________________________________\n",
      "Class:  0  elements:  68\n",
      "Class:  8  elements:  24\n",
      "\n",
      "Digits to classify: [0, 8]\n",
      "Testing:  80.0 %\n",
      "total tests: 371\n",
      "passed tests: 351\n",
      "accuracy:  94.60916442048517  %\n",
      "misclassification number:  5.390835579514828  %\n",
      "_________________________________\n",
      "Class:  0  elements:  60\n",
      "Class:  6  elements:  34\n",
      "\n",
      "Digits to classify: [0, 6]\n",
      "Testing:  80.0 %\n",
      "total tests: 376\n",
      "passed tests: 354\n",
      "accuracy:  94.14893617021278  %\n",
      "misclassification number:  5.851063829787222  %\n",
      "_________________________________\n"
     ]
    }
   ],
   "source": [
    "def mnist_svd(digits, test_n = 0.8):\n",
    "    \n",
    "    # Load the data\n",
    "    data = scipy.io.loadmat(r'.\\data\\MNIST.mat')\n",
    "\n",
    "    X = data['X']\n",
    "    I = data['I']\n",
    "    I = I[0,:]\n",
    "\n",
    "    # Extract the subdataset of X that contains all the digits specified in the corresponding array \n",
    "    # (in each cycle extracts the columns corresponding to a label)\n",
    "\n",
    "    searchd_class_mask = np.zeros(len(I), dtype=bool)\n",
    "    for i in range(len(I)):\n",
    "        for d in digits:\n",
    "            if (I[i] == d):\n",
    "                searchd_class_mask[i] = True\n",
    "                \n",
    "    X= X[:, searchd_class_mask]\n",
    "    I = I[searchd_class_mask]\n",
    "\n",
    "    # Separate training and test\n",
    "\n",
    "    X_train, X_test, I_train, I_test = train_test_split(X.T, I, test_size=test_n, random_state=42)\n",
    "\n",
    "    X_train = X_train.T\n",
    "    X_test = X_test.T\n",
    "\n",
    "    # Create the matrices X_part, one for each class\n",
    "    X_part = []\n",
    "    for i in range(len(digits)):\n",
    "        X_part.append(X_train[:, I_train == digits[i]])\n",
    "    \n",
    "    # print number of elements used for training on each class\n",
    "    for d in digits:\n",
    "        nelements = I_train[I_train==d]\n",
    "        print(\"Class: \", d ,\" elements: \", len(nelements))\n",
    "        \n",
    " \n",
    "    # Compute the SVD decomposition of the X_part matrices\n",
    "    U = []\n",
    "    for i in range(len(digits)):\n",
    "        u, _, _ = np.linalg.svd(X_part[i], full_matrices=False)\n",
    "        U.append(u)\n",
    "\n",
    "    # Take a new, unknown digit for the test set.\n",
    "\n",
    "    test_passed = 0\n",
    "\n",
    "    for i in range (len(I_test)):\n",
    "        y = X_test[:, i]\n",
    "\n",
    "        #plt.imshow(np.reshape(y,(16, 16)), cmap='gray')\n",
    "        #plt.show()\n",
    "        \n",
    "        # Compute the projections of y into the (trained images) spaces\n",
    "        y_projection = []\n",
    "        for z in range(len(digits)):\n",
    "            y_projection.append(U[z] @ (U[z].T @ y))\n",
    "\n",
    "        # Compute the distances\n",
    "        d = []\n",
    "        for j in range(len(digits)):\n",
    "            d.append(np.linalg.norm((y-y_projection[j]),2))\n",
    "\n",
    "        # Assign to the predicted class\n",
    "        for k in range(len(digits)):\n",
    "            if (d[k] == min(d)):\n",
    "                predicted_class = \"c\" + str(k)\n",
    "                predicted = digits[k]\n",
    "                \n",
    "        if predicted == I_test[i]:\n",
    "            test_passed = test_passed + 1\n",
    "                        \n",
    "        # Print out\n",
    "        #print(\"Predicted: \", predicted,\"     Truth:\", I_test[i],\"  Result:  \", (predicted == I_test[i]))\n",
    "    \n",
    "    print(\"\\n\"+\"Digits to classify: \" + str(digits))\n",
    "    print(\"Testing: \",test_n*100,\"%\" )\n",
    "    print(\"total tests: \" + str(len(I_test)))\n",
    "    print(\"passed tests: \" + str(test_passed))\n",
    "    accuracy = test_passed/len(I_test)*100\n",
    "    print(\"accuracy: \",accuracy,\" %\")\n",
    "    print(\"misclassification number: \",100-accuracy, \" %\")\n",
    "    print(\"_________________________________\")\n",
    "    \n",
    "    \n",
    "\n",
    "digits = [3, 4]    \n",
    "mnist_svd(digits,0.2)\n",
    "\n",
    "    \n",
    "digits = [3, 4]    \n",
    "mnist_svd(digits)\n",
    "\n",
    "\n",
    "digits = [1, 4]    \n",
    "mnist_svd(digits)\n",
    "\n",
    "\n",
    "digits = [8, 9]    \n",
    "mnist_svd(digits)\n",
    "\n",
    "\n",
    "digits = [5, 6]    \n",
    "mnist_svd(digits)\n",
    "\n",
    "digits = [3, 8]    \n",
    "mnist_svd(digits)\n",
    "\n",
    "digits = [1, 7]    \n",
    "mnist_svd(digits)\n",
    "\n",
    "digits = [0, 8]    \n",
    "mnist_svd(digits)\n",
    "\n",
    "digits = [0, 6]    \n",
    "mnist_svd(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da2e643",
   "metadata": {},
   "source": [
    "The misclassification error for the classification of 3 and 4 is quite low ~2% : this feature depends a lot from the fraction of the dataset used for training (changing the **random choice seed to choose the training column** is a big factor in this process).\n",
    "\n",
    "The fact that the training set may be chosen in un **unbalanced** way (that may contain an unequal number of 3s and 4s) can cause our tool to be trained more in recognizing one digit instead of the other digit (especially if they're similar).\n",
    "\n",
    "Using an 80-20 configuration for training and testing we have an overfitted model, that gives an higher percentage of misclassification error for unseen (test) data.\n",
    "\n",
    "Moreover we should highlight that most of the errors depend from the fact that some numbers are not well written and easily distinguishable from others (even by humans). In some cases, like the number 0, we have many similar numbers due to the **roundness** (3,5,6,8,9) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e547bb5",
   "metadata": {},
   "source": [
    "## Second Exercise N-Class classification algorithm \n",
    "The extension of this idea to the multiple classification task is trivial. Indeed, if we have more than\n",
    "2 classes (say, $k$ different classes) $C_1,...,C_k$, we just need to repeat the same procedure as before for\n",
    "each matrix $X_1,...,X_k$ to obtain the distances $d_1,...,d_k$. Then, the new digit $y$ will be classified as\n",
    "$C_i$ if $d_i$ is lower that $d_j$ for each $j = 1,...,k$.\n",
    "Repeat the exercise above with a 3-digit example. Comment the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "096ec74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  1  elements:  51\n",
      "Class:  2  elements:  45\n",
      "Class:  3  elements:  21\n",
      "\n",
      "Digits to classify: [1, 2, 3]\n",
      "Testing:  80.0 %\n",
      "total tests: 468\n",
      "passed tests: 448\n",
      "accuracy:  95.72649572649573  %\n",
      "misclassification number:  4.2735042735042725  %\n",
      "_________________________________\n",
      "Class:  1  elements:  52\n",
      "Class:  8  elements:  31\n",
      "Class:  0  elements:  60\n",
      "\n",
      "Digits to classify: [1, 8, 0]\n",
      "Testing:  80.0 %\n",
      "total tests: 572\n",
      "passed tests: 550\n",
      "accuracy:  96.15384615384616  %\n",
      "misclassification number:  3.8461538461538396  %\n",
      "_________________________________\n",
      "Class:  7  elements:  39\n",
      "Class:  5  elements:  15\n",
      "Class:  0  elements:  60\n",
      "\n",
      "Digits to classify: [7, 5, 0]\n",
      "Testing:  80.0 %\n",
      "total tests: 459\n",
      "passed tests: 421\n",
      "accuracy:  91.72113289760348  %\n",
      "misclassification number:  8.278867102396518  %\n",
      "_________________________________\n",
      "Class:  1  elements:  50\n",
      "Class:  2  elements:  43\n",
      "Class:  3  elements:  29\n",
      "Class:  4  elements:  21\n",
      "Class:  5  elements:  19\n",
      "Class:  6  elements:  27\n",
      "Class:  7  elements:  40\n",
      "Class:  8  elements:  31\n",
      "Class:  9  elements:  24\n",
      "Class:  0  elements:  57\n",
      "\n",
      "Digits to classify: [1, 2, 3, 4, 5, 6, 7, 8, 9, 0]\n",
      "Testing:  80.0 %\n",
      "total tests: 1366\n",
      "passed tests: 1236\n",
      "accuracy:  90.48316251830161  %\n",
      "misclassification number:  9.516837481698389  %\n",
      "_________________________________\n",
      "Class:  1  elements:  191\n",
      "Class:  2  elements:  169\n",
      "Class:  3  elements:  113\n",
      "Class:  4  elements:  90\n",
      "Class:  5  elements:  76\n",
      "Class:  6  elements:  118\n",
      "Class:  7  elements:  135\n",
      "Class:  8  elements:  112\n",
      "Class:  9  elements:  109\n",
      "Class:  0  elements:  252\n",
      "\n",
      "Digits to classify: [1, 2, 3, 4, 5, 6, 7, 8, 9, 0]\n",
      "Testing:  20.0 %\n",
      "total tests: 342\n",
      "passed tests: 131\n",
      "accuracy:  38.30409356725146  %\n",
      "misclassification number:  61.69590643274854  %\n",
      "_________________________________\n"
     ]
    }
   ],
   "source": [
    "digits = [1, 2, 3]    \n",
    "mnist_svd(digits)\n",
    "\n",
    "digits = [1, 8, 0]    \n",
    "mnist_svd(digits)\n",
    "\n",
    "digits = [7, 5, 0]    \n",
    "mnist_svd(digits)\n",
    "\n",
    "digits = [1, 2, 3, 4, 5, 6, 7, 8, 9, 0]    \n",
    "mnist_svd(digits)\n",
    "mnist_svd(digits,0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b42197",
   "metadata": {},
   "source": [
    "Indeed, changing the number of classes to be identified, misclassification **error increases due to the multiplicity of the distances calculated**, which (as said in the prevoius point) depends on the images chosen for the training set. The observations done in the previous part have an amplified effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad58edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
